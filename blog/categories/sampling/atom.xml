<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Sampling | lvpengwei’s Blog]]></title>
  <link href="http://lvpengwei.github.io//blog/categories/sampling/atom.xml" rel="self"/>
  <link href="http://lvpengwei.github.io//"/>
  <updated>2023-04-14T20:33:13+08:00</updated>
  <id>http://lvpengwei.github.io//</id>
  <author>
    <name><![CDATA[lvpengwei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[纹理局部采样]]></title>
    <link href="http://lvpengwei.github.io//blog/2021/08/05/wen-li-ju-bu-cai-yang/"/>
    <updated>2021-08-05T17:21:42+08:00</updated>
    <id>http://lvpengwei.github.io//blog/2021/08/05/wen-li-ju-bu-cai-yang</id>
    <content type="html"><![CDATA[<h2>现象</h2>

<p>在使用 MediaCodec 解码视频获取到纹理时，它会给出一个 cropRect 来裁剪多余的绿色像素。当拿着这个纹理和对应的 cropRect 去上屏的时候，发现在边缘的地方有一像素绿边。</p>

<p>如图所示，解码出的纹理大小是 <code>1920*1088</code>，有 8 像素的绿边；裁剪后大小是 <code>1920*1080</code>，有 1 像素绿边。</p>

<h4>解码图片</h4>

<p><img src="/images/20210805/decoded_image.png" width="480" alt="" /></p>

<h4>裁剪后</h4>

<p><img src="/images/20210805/crop_image.png" width="480" alt="" /></p>

<h2>纹素和像素的映射关系</h2>

<p>一开始怀疑是纹素和像素的坐标系不一致的问题，对纹理坐标减了 0.5，发现还是有绿边。然后还找到坐标系不一致的问题只存在于 D3D9，后续的 D3D10 修改了坐标系的对应关系，而且 OpenGL 的坐标系一直没这个问题。</p>

<h2>收缩 0.5 纹素</h2>

<p>在<a href="https://stackoverflow.com/questions/6023400/opengl-es-texture-coordinates-slightly-off">OpenGL ES Texture Coordinates Slightly Off</a>上看到说只有当采样的点在纹素中心，才返回准确的颜色，否则就是插值出来的。也就是当采样的点在纹素中心和边界之间时，可能就会采到超出边界的颜色。</p>

<h2>查 Android 源码</h2>

<p>同时也发现使用<code>SurfaceTexture.getTransformMatrix</code>得到的 matrix 时，画面是正常的，所以去查看了 Android 的源码，想知道这个 matrix 是怎么生成的。</p>

<p>生成的逻辑就是下面这段代码，可以看到注释说为了防止双线性采样超过裁剪边缘，普通纹理需要收缩 0.5 纹素，YUV420的要收缩 1.0 纹素。</p>

<pre><code class="cpp">......
......
void SurfaceTexture::computeTransformMatrix(float outTransform[16], const sp&lt;GraphicBuffer&gt;&amp; buf,
                                            const Rect&amp; cropRect, uint32_t transform,
                                            bool filtering) {
    ......
    if (!cropRect.isEmpty() &amp;&amp; buf.get()) {
        float tx = 0.0f, ty = 0.0f, sx = 1.0f, sy = 1.0f;
        float bufferWidth = buf-&gt;getWidth();
        float bufferHeight = buf-&gt;getHeight();
        float shrinkAmount = 0.0f;
        if (filtering) {
            // In order to prevent bilinear sampling beyond the edge of the
            // crop rectangle we may need to shrink it by 2 texels in each
            // dimension.  Normally this would just need to take 1/2 a texel
            // off each end, but because the chroma channels of YUV420 images
            // are subsampled we may need to shrink the crop region by a whole
            // texel on each side.
            switch (buf-&gt;getPixelFormat()) {
                case PIXEL_FORMAT_RGBA_8888:
                case PIXEL_FORMAT_RGBX_8888:
                case PIXEL_FORMAT_RGBA_FP16:
                case PIXEL_FORMAT_RGBA_1010102:
                case PIXEL_FORMAT_RGB_888:
                case PIXEL_FORMAT_RGB_565:
                case PIXEL_FORMAT_BGRA_8888:
                    // We know there's no subsampling of any channels, so we
                    // only need to shrink by a half a pixel.
                    shrinkAmount = 0.5;
                    break;

                default:
                    // If we don't recognize the format, we must assume the
                    // worst case (that we care about), which is YUV420.
                    shrinkAmount = 1.0;
                    break;
            }
        }

        // Only shrink the dimensions that are not the size of the buffer.
        if (cropRect.width() &lt; bufferWidth) {
            tx = (float(cropRect.left) + shrinkAmount) / bufferWidth;
            sx = (float(cropRect.width()) - (2.0f * shrinkAmount)) / bufferWidth;
        }
        if (cropRect.height() &lt; bufferHeight) {
            ty = (float(bufferHeight - cropRect.bottom) + shrinkAmount) / bufferHeight;
            sy = (float(cropRect.height()) - (2.0f * shrinkAmount)) / bufferHeight;
        }

        mat4 crop(sx, 0, 0, 0, 0, sy, 0, 0, 0, 0, 1, 0, tx, ty, 0, 1);
        xform = crop * xform;
    }
    ......
}
......
......
</code></pre>

<p>再看一遍<a href="https://developer.android.com/reference/android/graphics/SurfaceTexture#getTransformMatrix(float[]">SurfaceTexture.getTransformMatrix</a>)发现也有说明。</p>

<p><img src="/images/20210805/getTransformMatrix.png" width="600" alt="" /></p>

<h2>双线性插值（Bilinear Filtering）</h2>

<p> 双线性插值会取临近 4 个像素的加权平均值。</p>

<p><img src="https://s2.loli.net/2021/12/11/hgFatmDMCX15T6d.jpg" width="500" alt="bilinear_filtering.jpg" /></p>

<p>上面的情况我们在传递的是图片边缘的 UV 坐标，那么由于双线性采样，它就会采到下面绿色的像素；如果我们传递的 UV 坐标收缩 0.5px，那么边缘外面的像素权重会是 0，就采不到绿色。</p>

<h2>链接</h2>

<p><a href="https://stackoverflow.com/questions/6023400/opengl-es-texture-coordinates-slightly-off">OpenGL ES Texture Coordinates Slightly Off</a><br/>
<a href="https://cs.android.com/android/platform/superproject/+/master:frameworks/native/libs/nativedisplay/surfacetexture/SurfaceTexture.cpp;l=275;drc=master;bpv=0;bpt=1">SurfaceTexture::computeTransformMatrix</a><br/>
<a href="https://developer.android.com/reference/android/graphics/SurfaceTexture#getTransformMatrix(float[]">SurfaceTexture.getTransformMatrix</a>)<br/>
<a href="https://zhuanlan.zhihu.com/p/143377682">图形学底层探秘 - 纹理采样、环绕、过滤与Mipmap的那些事</a><br/>
<a href="https://docs.microsoft.com/en-us/windows/win32/direct3d9/directly-mapping-texels-to-pixels">Directly Mapping Texels to Pixels (Direct3D 9)</a></p>
]]></content>
  </entry>
  
</feed>
